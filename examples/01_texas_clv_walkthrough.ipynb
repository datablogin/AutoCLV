{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas CLV Complete Walkthrough\n",
    "\n",
    "This notebook demonstrates a complete Customer Lifetime Value (CLV) analysis workflow using the AutoCLV library with synthetic Texas customer data.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Generate realistic synthetic customer data\n",
    "2. Build a customer data mart with period aggregations\n",
    "3. Run Five Lenses analyses (Lens 1-3)\n",
    "4. Calculate RFM scores and segment customers\n",
    "5. Train CLV models (BG/NBD + Gamma-Gamma)\n",
    "6. Generate CLV predictions and insights\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠️ Data Privacy Notice\n",
    "\n",
    "**This notebook uses synthetic data for demonstration purposes.**\n",
    "\n",
    "When adapting this workflow to production data:\n",
    "- Ensure compliance with data privacy regulations (GDPR, CCPA, etc.)\n",
    "- Anonymize or pseudonymize customer identifiers\n",
    "- Implement appropriate access controls\n",
    "- Never commit notebooks with real customer data to version control\n",
    "- Consider using differential privacy techniques for sensitive analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Data\n",
    "\n",
    "We'll use the Texas CLV generator to create realistic customer transaction data across 4 Texas cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "from customer_base_audit.synthetic.texas_clv_client import generate_texas_clv_client\n",
    "\n",
    "# Generate 1000 customers with transactions over 2024\n",
    "customers, transactions, city_map = generate_texas_clv_client(\n",
    "    total_customers=1000,\n",
    "    seed=42,  # Fixed seed for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(customers):,} customers\")\n",
    "print(f\"Generated {len(transactions):,} transactions\")\n",
    "print(f\"Cities: {set(city_map.values())}\")\n",
    "print(\n",
    "    f\"\\nDate range: {min(t.event_ts for t in transactions).date()} to {max(t.event_ts for t in transactions).date()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the Data\n",
    "\n",
    "Let's examine the structure of our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrames for easy exploration\n",
    "customers_df = pd.DataFrame([asdict(c) for c in customers])\n",
    "transactions_df = pd.DataFrame([asdict(t) for t in transactions])\n",
    "\n",
    "print(\"=== Customer Sample ===\")\n",
    "print(customers_df.head())\n",
    "print(\"\\nCustomers by city:\")\n",
    "print(customers_df[\"customer_id\"].map(city_map).value_counts())\n",
    "\n",
    "print(\"\\n=== Transaction Sample ===\")\n",
    "print(transactions_df.head())\n",
    "\n",
    "print(\"\\n=== Transaction Statistics ===\")\n",
    "print(\n",
    "    f\"Total revenue: ${transactions_df['quantity'].astype(float) * transactions_df['unit_price'].astype(float).sum():,.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Average order value: ${(transactions_df['quantity'].astype(float) * transactions_df['unit_price'].astype(float)).mean():,.2f}\"\n",
    ")\n",
    "print(f\"Unique products: {transactions_df['product_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Customer Data Mart\n",
    "\n",
    "The data mart aggregates transactions by customer and time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.foundation.data_mart import (\n",
    "    CustomerDataMartBuilder,\n",
    "    PeriodGranularity,\n",
    ")\n",
    "\n",
    "# Build data mart with monthly granularity\n",
    "builder = CustomerDataMartBuilder(period_granularities=[PeriodGranularity.MONTH])\n",
    "mart = builder.build([asdict(t) for t in transactions])\n",
    "\n",
    "print(f\"Orders processed: {len(mart.orders):,}\")\n",
    "print(f\"Monthly periods: {len(mart.periods[PeriodGranularity.MONTH]):,}\")\n",
    "print(\n",
    "    f\"Unique customers: {len(set(p.customer_id for p in mart.periods[PeriodGranularity.MONTH])):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate RFM Metrics\n",
    "\n",
    "RFM (Recency, Frequency, Monetary) analysis helps segment customers by behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.foundation.rfm import calculate_rfm, calculate_rfm_scores\n",
    "\n",
    "# Calculate RFM metrics\n",
    "period_aggregations = mart.periods[PeriodGranularity.MONTH]\n",
    "observation_end = datetime(2024, 12, 31, 23, 59, 59)\n",
    "\n",
    "rfm_metrics = calculate_rfm(\n",
    "    period_aggregations=period_aggregations, observation_end=observation_end\n",
    ")\n",
    "\n",
    "rfm_scores = calculate_rfm_scores(rfm_metrics)\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "rfm_df = pd.DataFrame([asdict(rfm) for rfm in rfm_metrics])\n",
    "scores_df = pd.DataFrame([asdict(s) for s in rfm_scores])\n",
    "\n",
    "print(\"=== RFM Metrics Summary ===\")\n",
    "print(rfm_df[[\"recency_days\", \"frequency\", \"monetary\"]].describe())\n",
    "\n",
    "print(\"\\n=== RFM Scores Distribution ===\")\n",
    "print(\n",
    "    f\"Best customers (555): {len(scores_df[(scores_df['r_score'] == 5) & (scores_df['f_score'] == 5) & (scores_df['m_score'] == 5)])}\"\n",
    ")\n",
    "print(\n",
    "    f\"At-risk customers (111): {len(scores_df[(scores_df['r_score'] == 1) & (scores_df['f_score'] == 1) & (scores_df['m_score'] == 1)])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Lens 1 - Single Period Analysis\n",
    "\n",
    "Lens 1 provides a snapshot view of your customer base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.analyses.lens1 import analyze_single_period\n",
    "\n",
    "lens1_results = analyze_single_period(rfm_metrics, rfm_scores)\n",
    "\n",
    "print(\"=== Lens 1: Single Period Analysis ===\")\n",
    "print(f\"Total Customers: {lens1_results.total_customers:,}\")\n",
    "print(\n",
    "    f\"One-Time Buyers: {lens1_results.one_time_buyers:,} ({lens1_results.one_time_buyer_pct:.1f}%)\"\n",
    ")\n",
    "print(f\"Total Revenue: ${lens1_results.total_revenue:,.2f}\")\n",
    "print(\"\\nRevenue Concentration:\")\n",
    "print(f\"  Top 10% contribute: {lens1_results.top_10pct_revenue_contribution:.1f}%\")\n",
    "print(f\"  Top 20% contribute: {lens1_results.top_20pct_revenue_contribution:.1f}%\")\n",
    "print(\"\\nCustomer Metrics:\")\n",
    "print(f\"  Avg orders per customer: {lens1_results.avg_orders_per_customer:.1f}\")\n",
    "print(f\"  Median customer value: ${lens1_results.median_customer_value:.2f}\")\n",
    "\n",
    "if lens1_results.rfm_distribution:\n",
    "    print(\"\\nTop 5 RFM Segments:\")\n",
    "    sorted_segments = sorted(\n",
    "        lens1_results.rfm_distribution.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:5]\n",
    "    for segment, count in sorted_segments:\n",
    "        print(f\"  {segment}: {count} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Lens 2 - Period-to-Period Comparison\n",
    "\n",
    "Lens 2 compares two time periods to analyze customer migration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.analyses.lens2 import analyze_period_comparison\n",
    "\n",
    "# Compare Q3 vs Q4 2024\n",
    "period1_start = datetime(2024, 7, 1)\n",
    "period1_end = datetime(2024, 9, 30, 23, 59, 59)\n",
    "period2_start = datetime(2024, 10, 1)\n",
    "period2_end = datetime(2024, 12, 31, 23, 59, 59)\n",
    "\n",
    "period1_aggs = [\n",
    "    agg\n",
    "    for agg in period_aggregations\n",
    "    if period1_start <= agg.period_start <= period1_end\n",
    "]\n",
    "period2_aggs = [\n",
    "    agg\n",
    "    for agg in period_aggregations\n",
    "    if period2_start <= agg.period_start <= period2_end\n",
    "]\n",
    "\n",
    "period1_rfm = calculate_rfm(period1_aggs, observation_end=period1_end)\n",
    "period2_rfm = calculate_rfm(period2_aggs, observation_end=period2_end)\n",
    "\n",
    "all_customer_ids = list(set(c.customer_id for c in customers))\n",
    "\n",
    "lens2_results = analyze_period_comparison(\n",
    "    period1_rfm=period1_rfm,\n",
    "    period2_rfm=period2_rfm,\n",
    "    all_customer_history=all_customer_ids,\n",
    ")\n",
    "\n",
    "print(\"=== Lens 2: Q3 → Q4 2024 Comparison ===\")\n",
    "print(\"\\nCustomer Migration:\")\n",
    "print(f\"  Retained: {len(lens2_results.migration.retained):,}\")\n",
    "print(f\"  Churned: {len(lens2_results.migration.churned):,}\")\n",
    "print(f\"  New: {len(lens2_results.migration.new):,}\")\n",
    "print(f\"  Reactivated: {len(lens2_results.migration.reactivated):,}\")\n",
    "\n",
    "print(\"\\nRetention Metrics:\")\n",
    "print(f\"  Retention Rate: {lens2_results.retention_rate:.1f}%\")\n",
    "print(f\"  Churn Rate: {lens2_results.churn_rate:.1f}%\")\n",
    "print(f\"  Reactivation Rate: {lens2_results.reactivation_rate:.1f}%\")\n",
    "\n",
    "print(\"\\nBusiness Metrics:\")\n",
    "print(f\"  Customer Count Change: {lens2_results.customer_count_change:+d}\")\n",
    "print(f\"  Revenue Change: {lens2_results.revenue_change_pct:+.1f}%\")\n",
    "print(f\"  AOV Change: {lens2_results.avg_order_value_change_pct:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Lens 3 - Single Cohort Evolution\n",
    "\n",
    "Lens 3 tracks how a cohort's behavior evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.foundation.cohorts import (\n",
    "    create_monthly_cohorts,\n",
    "    assign_cohorts,\n",
    ")\n",
    "from customer_base_audit.analyses.lens3 import analyze_cohort_evolution\n",
    "\n",
    "# Create monthly cohorts\n",
    "cohort_definitions = create_monthly_cohorts(\n",
    "    customers=customers,\n",
    "    start_date=datetime(2024, 1, 1),\n",
    "    end_date=datetime(2024, 12, 31),\n",
    ")\n",
    "\n",
    "cohort_assignments = assign_cohorts(customers, cohort_definitions)\n",
    "\n",
    "# Analyze January 2024 cohort\n",
    "cohort_name = \"2024-01\"\n",
    "cohort_customer_ids = [\n",
    "    cust_id for cust_id, coh_id in cohort_assignments.items() if coh_id == cohort_name\n",
    "]\n",
    "\n",
    "cohort_definition = next(c for c in cohort_definitions if c.cohort_id == cohort_name)\n",
    "\n",
    "lens3_results = analyze_cohort_evolution(\n",
    "    cohort_name=cohort_name,\n",
    "    acquisition_date=cohort_definition.period_start,\n",
    "    period_aggregations=period_aggregations,\n",
    "    cohort_customer_ids=cohort_customer_ids,\n",
    ")\n",
    "\n",
    "print(f\"=== Lens 3: {cohort_name} Cohort Evolution ===\")\n",
    "print(f\"Cohort Size: {lens3_results.cohort_size:,}\")\n",
    "print(\"\\nPeriod-by-Period Metrics:\")\n",
    "\n",
    "for period in lens3_results.periods[:6]:  # First 6 months\n",
    "    print(f\"\\nPeriod {period.period_number}:\")\n",
    "    print(f\"  Active Customers: {period.active_customers:,}\")\n",
    "    print(f\"  Retention Rate: {period.retention_rate:.1%}\")\n",
    "    print(f\"  Avg Orders: {period.avg_orders_per_customer:.2f}\")\n",
    "    print(f\"  Avg Revenue: ${period.avg_revenue_per_customer:,.2f}\")\n",
    "    print(f\"  Total Revenue: ${period.total_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Model Input Data\n",
    "\n",
    "Format data for CLV model training (BG/NBD + Gamma-Gamma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.models.model_prep import prepare_clv_model_inputs\n",
    "\n",
    "# Prepare data for BG/NBD (purchase frequency) and Gamma-Gamma (monetary value) models\n",
    "model_data = prepare_clv_model_inputs(\n",
    "    transactions=[asdict(t) for t in transactions],\n",
    "    observation_start=datetime(2024, 1, 1),\n",
    "    observation_end=datetime(2024, 12, 31, 23, 59, 59),\n",
    "    customer_id_field=\"customer_id\",\n",
    "    timestamp_field=\"event_ts\",\n",
    "    monetary_field=\"unit_price\",\n",
    ")\n",
    "\n",
    "print(\"=== CLV Model Input Data ===\")\n",
    "print(model_data.head())\n",
    "print(f\"\\nTotal customers: {len(model_data)}\")\n",
    "print(\n",
    "    f\"Customers with 2+ purchases (eligible for Gamma-Gamma): {len(model_data[model_data['frequency'] >= 2])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train BG/NBD Model (Purchase Frequency)\n",
    "\n",
    "The BG/NBD model predicts how many purchases a customer will make in a future time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.models.bg_nbd import BGNBDModelWrapper, BGNBDConfig\n",
    "\n",
    "# Train BG/NBD model using MAP method (faster than MCMC)\n",
    "config = BGNBDConfig(method=\"map\")\n",
    "bg_nbd_model = BGNBDModelWrapper(config)\n",
    "\n",
    "print(\"Training BG/NBD model (this may take a minute)...\")\n",
    "bg_nbd_model.fit(model_data)\n",
    "print(\"✓ BG/NBD model trained successfully\")\n",
    "\n",
    "# Predict purchases for next 90 days\n",
    "purchase_predictions = bg_nbd_model.predict_purchases(model_data, time_periods=90.0)\n",
    "\n",
    "print(\"\\n=== Purchase Predictions (Next 90 Days) ===\")\n",
    "print(purchase_predictions.describe())\n",
    "print(\"\\nTop 5 customers by predicted purchases:\")\n",
    "print(purchase_predictions.nlargest(5, \"predicted_purchases\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Train Gamma-Gamma Model (Monetary Value)\n",
    "\n",
    "The Gamma-Gamma model predicts average transaction value per customer.\n",
    "\n",
    "**Why 2+ purchases?** The Gamma-Gamma model requires customers to have made at least 2 purchases to estimate their average transaction value. This mathematical requirement ensures the model has enough data points to distinguish between a customer's \"true\" average spend and random variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_base_audit.models.gamma_gamma import (\n",
    "    GammaGammaModelWrapper,\n",
    "    GammaGammaConfig,\n",
    ")\n",
    "\n",
    "# Filter to customers with 2+ purchases (Gamma-Gamma requirement)\n",
    "gamma_data = model_data[model_data[\"frequency\"] >= 2].copy()\n",
    "\n",
    "print(f\"Training Gamma-Gamma model on {len(gamma_data)} customers with 2+ purchases...\")\n",
    "\n",
    "gg_config = GammaGammaConfig(method=\"map\")\n",
    "gamma_gamma_model = GammaGammaModelWrapper(gg_config)\n",
    "gamma_gamma_model.fit(gamma_data)\n",
    "print(\"✓ Gamma-Gamma model trained successfully\")\n",
    "\n",
    "# Predict average transaction value\n",
    "spend_predictions = gamma_gamma_model.predict_spend(gamma_data)\n",
    "\n",
    "print(\"\\n=== Spend Predictions (Avg Transaction Value) ===\")\n",
    "print(spend_predictions.describe())\n",
    "print(\"\\nTop 5 customers by predicted spend:\")\n",
    "print(spend_predictions.nlargest(5, \"predicted_avg_spend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Calculate Customer Lifetime Value\n",
    "\n",
    "Combine purchase frequency and monetary value predictions to estimate CLV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge purchase and spend predictions\n",
    "clv_data = purchase_predictions.merge(spend_predictions, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Calculate 90-day CLV = predicted purchases × predicted avg spend\n",
    "clv_data[\"clv_90_day\"] = (\n",
    "    clv_data[\"predicted_purchases\"] * clv_data[\"predicted_avg_spend\"]\n",
    ")\n",
    "\n",
    "# Calculate probability alive for active customers\n",
    "prob_alive = bg_nbd_model.calculate_probability_alive(gamma_data)\n",
    "clv_data = clv_data.merge(prob_alive, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Adjust CLV by probability alive\n",
    "clv_data[\"clv_90_day_adjusted\"] = clv_data[\"clv_90_day\"] * clv_data[\n",
    "    \"prob_alive\"\n",
    "].fillna(1.0)\n",
    "\n",
    "print(\"=== Customer Lifetime Value (90-Day Predictions) ===\")\n",
    "print(clv_data[[\"clv_90_day\", \"clv_90_day_adjusted\", \"prob_alive\"]].describe())\n",
    "\n",
    "print(\n",
    "    f\"\\nTotal predicted 90-day revenue: ${clv_data['clv_90_day_adjusted'].sum():,.2f}\"\n",
    ")\n",
    "print(f\"Average CLV per customer: ${clv_data['clv_90_day_adjusted'].mean():,.2f}\")\n",
    "\n",
    "print(\"\\n=== Top 10 Customers by CLV ===\")\n",
    "top_customers = clv_data.nlargest(10, \"clv_90_day_adjusted\")[\n",
    "    [\n",
    "        \"customer_id\",\n",
    "        \"predicted_purchases\",\n",
    "        \"predicted_avg_spend\",\n",
    "        \"prob_alive\",\n",
    "        \"clv_90_day_adjusted\",\n",
    "    ]\n",
    "]\n",
    "for idx, row in top_customers.iterrows():\n",
    "    print(\n",
    "        f\"{row['customer_id']}: ${row['clv_90_day_adjusted']:.2f} ({row['predicted_purchases']:.1f} purchases @ ${row['predicted_avg_spend']:.2f}, {row['prob_alive']:.1%} alive)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Visualize Results\n",
    "\n",
    "Create visualizations to understand customer segments and CLV distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. CLV Distribution\n",
    "axes[0, 0].hist(clv_data[\"clv_90_day_adjusted\"], bins=50, edgecolor=\"black\")\n",
    "axes[0, 0].set_xlabel(\"90-Day CLV ($)\")\n",
    "axes[0, 0].set_ylabel(\"Number of Customers\")\n",
    "axes[0, 0].set_title(\"CLV Distribution\")\n",
    "axes[0, 0].axvline(\n",
    "    clv_data[\"clv_90_day_adjusted\"].median(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Median: ${clv_data['clv_90_day_adjusted'].median():.2f}\",\n",
    ")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Purchase Frequency vs Monetary Value\n",
    "axes[0, 1].scatter(\n",
    "    clv_data[\"predicted_purchases\"], clv_data[\"predicted_avg_spend\"], alpha=0.5\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Predicted Purchases (90 days)\")\n",
    "axes[0, 1].set_ylabel(\"Predicted Avg Spend ($)\")\n",
    "axes[0, 1].set_title(\"Purchase Frequency vs Monetary Value\")\n",
    "\n",
    "# 3. Probability Alive Distribution\n",
    "axes[1, 0].hist(clv_data[\"prob_alive\"].dropna(), bins=30, edgecolor=\"black\")\n",
    "axes[1, 0].set_xlabel(\"Probability Alive\")\n",
    "axes[1, 0].set_ylabel(\"Number of Customers\")\n",
    "axes[1, 0].set_title(\"Customer Activity Probability\")\n",
    "\n",
    "# 4. Top 20 Customers by CLV\n",
    "top_20 = clv_data.nlargest(20, \"clv_90_day_adjusted\")\n",
    "axes[1, 1].barh(range(len(top_20)), top_20[\"clv_90_day_adjusted\"])\n",
    "axes[1, 1].set_yticks(range(len(top_20)))\n",
    "axes[1, 1].set_yticklabels(top_20[\"customer_id\"].str[:10])  # Truncate IDs\n",
    "axes[1, 1].set_xlabel(\"90-Day CLV ($)\")\n",
    "axes[1, 1].set_title(\"Top 20 Customers by CLV\")\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. ✅ Generated 1,000 customers with realistic synthetic transaction data\n",
    "2. ✅ Built a customer data mart with monthly aggregations\n",
    "3. ✅ Calculated RFM metrics and segmented customers\n",
    "4. ✅ Ran Five Lenses analyses (Lens 1-3)\n",
    "5. ✅ Trained BG/NBD model for purchase frequency prediction\n",
    "6. ✅ Trained Gamma-Gamma model for monetary value prediction\n",
    "7. ✅ Calculated 90-day CLV predictions for all customers\n",
    "8. ✅ Visualized customer segments and CLV distribution\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Customer Retention**: Check Lens 2 retention rate and Lens 1 one-time buyer percentage\n",
    "- **Revenue Concentration**: See Lens 1 top 10%/20% revenue contribution\n",
    "- **Cohort Health**: Review Lens 3 cohort evolution and retention decay\n",
    "- **CLV Distribution**: Understand which customers drive future revenue\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Compare multiple cohorts (see `02_custom_cohorts.ipynb`)\n",
    "- Benchmark different models (see `03_model_comparison.ipynb`)\n",
    "- Monitor model drift over time (see `04_monitoring_drift.ipynb`)\n",
    "- Apply to your own production data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}